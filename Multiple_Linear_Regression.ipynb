{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyURsEG4hgii",
        "outputId": "052b03ea-440e-405f-fe16-364667af9af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Student_Performance.csv\") # Reading and saving dataframe\n",
        "features = [\"Hours Studied\", \"Previous Scores\", \"Extracurricular Activities\", \"Sleep Hours\", \"Sample Question Papers Practiced\"]\n",
        "target = \"Performance Index\"\n",
        "\n",
        "df[\"Extracurricular Activities\"] = df[\"Extracurricular Activities\"].map({'Yes': 1, 'No': 0})\n",
        "X = df[features].values\n",
        "y = df[target].values.reshape(len(df[target].values), 1) # Equivalent y = df[target].values.reshape(-1, 1)\n",
        "X = torch.from_numpy(X).float()\n",
        "y = torch.from_numpy(y).float()\n",
        "print(\"Features: \", X)\n",
        "print(\"Features size: \", X.shape)\n",
        "print()\n",
        "print(\"Target: \", y)\n",
        "print(\"Target size: \", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DM_T1mZl2RX",
        "outputId": "3d43b962-1c24-41e3-a8f3-b77f65ad53e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features:  tensor([[ 7., 99.,  1.,  9.,  1.],\n",
            "        [ 4., 82.,  0.,  4.,  2.],\n",
            "        [ 8., 51.,  1.,  7.,  2.],\n",
            "        ...,\n",
            "        [ 6., 83.,  1.,  8.,  5.],\n",
            "        [ 9., 97.,  1.,  7.,  0.],\n",
            "        [ 7., 74.,  0.,  8.,  1.]])\n",
            "Features size:  torch.Size([10000, 5])\n",
            "\n",
            "Target:  tensor([[91.],\n",
            "        [65.],\n",
            "        [45.],\n",
            "        ...,\n",
            "        [74.],\n",
            "        [95.],\n",
            "        [64.]])\n",
            "Target size:  torch.Size([10000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(len(X) * 0.8)\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "print((len(X_train), len(y_train), len(X_test), len(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gt4BiTSnWQR",
        "outputId": "80012cf4-bf21-4eb2-e0b1-c312fd71b535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 8000, 2000, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.w1 = nn.Parameter(torch.randn(1,\n",
        "                                    requires_grad=True,\n",
        "                                    dtype=torch.float))\n",
        "    self.w2 = nn.Parameter(torch.randn(1,\n",
        "                                    requires_grad=True,\n",
        "                                    dtype=torch.float))\n",
        "    self.w3 = nn.Parameter(torch.randn(1,\n",
        "                                    requires_grad=True,\n",
        "                                    dtype=torch.float))\n",
        "    self.w4 = nn.Parameter(torch.randn(1,\n",
        "                                    requires_grad=True,\n",
        "                                    dtype=torch.float))\n",
        "    self.w5 = nn.Parameter(torch.randn(1,\n",
        "                                    requires_grad=True,\n",
        "                                    dtype=torch.float))\n",
        "    self.bias = nn.Parameter(torch.randn(1,\n",
        "                                    requires_grad=True,\n",
        "                                    dtype=torch.float))\n",
        "  def forward(self, hrs, prevScores, extraCurry, sleepHrs, sampleQp):\n",
        "    return hrs * self.w1 + prevScores * self.w2 + extraCurry * self.w3 + sleepHrs * self.w4 + sampleQp * self.w5 + self.bias\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_0 = LinearRegression()\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akUQe-Dsrc6D",
        "outputId": "edb36ac7-58f8-4f96-f426-1faea6ecd91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('w1', tensor([0.3367])),\n",
              "             ('w2', tensor([0.1288])),\n",
              "             ('w3', tensor([0.2345])),\n",
              "             ('w4', tensor([0.2303])),\n",
              "             ('w5', tensor([-1.1229])),\n",
              "             ('bias', tensor([-0.1863]))])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(),\n",
        "                            lr=0.001)\n",
        "\n",
        "# Standardize 'Previous Scores' using the mean and standard deviation from the training data\n",
        "mean_prev_scores = X_train[:, 1].mean()\n",
        "std_prev_scores = X_train[:, 1].std()\n",
        "\n",
        "X_train[:, 1] = (X_train[:, 1] - mean_prev_scores) / std_prev_scores\n",
        "X_test[:, 1] = (X_test[:, 1] - mean_prev_scores) / std_prev_scores\n",
        "\n",
        "print(\"Standardized X_train (first 5 rows of 'Previous Scores'):\", X_train[:5, 1])\n",
        "print(\"Standardized X_test (first 5 rows of 'Previous Scores'):\", X_test[:5, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r0LoDhhtxGI",
        "outputId": "b608263a-7f98-4346-860d-8a208733421c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardized X_train (first 5 rows of 'Previous Scores'): tensor([ 1.7030,  0.7236, -1.0621, -1.0045,  0.3204])\n",
            "Standardized X_test (first 5 rows of 'Previous Scores'): tensor([-1.1197, -1.2350,  0.4356,  0.9541,  0.7813])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 500\n",
        "for epoch in range(epochs):\n",
        "  model_0.train()\n",
        "  # 1. Forward pass\n",
        "  train_preds = model_0.forward(X_train[:, 0], X_train[:, 1], X_train[:, 2], X_train[:, 3], X_train[:, 4])\n",
        "\n",
        "  # 2. Compute loss\n",
        "  train_loss = loss_fn(train_preds, y_train)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. loss backward\n",
        "  train_loss.backward()\n",
        "\n",
        "  # 5. Optimizer step\n",
        "  optimizer.step()\n",
        "\n",
        "  model_0.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    test_preds = model_0.forward(X_test[:, 0], X_test[:, 1], X_test[:, 2], X_test[:, 3], X_test[:, 4])\n",
        "    test_loss = loss_fn(test_preds, y_test)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch} | Train loss: {train_loss} | Test loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1NGGETJQCwG",
        "outputId": "45ec57e6-8833-41e8-a939-13332f558792"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py:129: UserWarning: Using a target size (torch.Size([8000, 1])) that is different to the input size (torch.Size([8000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py:129: UserWarning: Using a target size (torch.Size([2000, 1])) that is different to the input size (torch.Size([2000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Train loss: 57.19602584838867 | Test loss: 57.47905731201172\n",
            "Epoch: 10 | Train loss: 57.02028274536133 | Test loss: 57.30193328857422\n",
            "Epoch: 20 | Train loss: 56.84455490112305 | Test loss: 57.12480926513672\n",
            "Epoch: 30 | Train loss: 56.66881561279297 | Test loss: 56.94768142700195\n",
            "Epoch: 40 | Train loss: 56.49308776855469 | Test loss: 56.77056121826172\n",
            "Epoch: 50 | Train loss: 56.31734848022461 | Test loss: 56.593441009521484\n",
            "Epoch: 60 | Train loss: 56.1416130065918 | Test loss: 56.416316986083984\n",
            "Epoch: 70 | Train loss: 55.96588134765625 | Test loss: 56.23918914794922\n",
            "Epoch: 80 | Train loss: 55.79014587402344 | Test loss: 56.06206130981445\n",
            "Epoch: 90 | Train loss: 55.61441421508789 | Test loss: 55.88494110107422\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py:129: UserWarning: Using a target size (torch.Size([2000, 1])) that is different to the input size (torch.Size([2000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py:129: UserWarning: Using a target size (torch.Size([8000, 1])) that is different to the input size (torch.Size([8000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100 | Train loss: 55.43867874145508 | Test loss: 55.70781326293945\n",
            "Epoch: 110 | Train loss: 55.262939453125 | Test loss: 55.53069305419922\n",
            "Epoch: 120 | Train loss: 55.08720779418945 | Test loss: 55.35356521606445\n",
            "Epoch: 130 | Train loss: 54.911476135253906 | Test loss: 55.17643737792969\n",
            "Epoch: 140 | Train loss: 54.735748291015625 | Test loss: 54.99932098388672\n",
            "Epoch: 150 | Train loss: 54.56001281738281 | Test loss: 54.82219696044922\n",
            "Epoch: 160 | Train loss: 54.38428497314453 | Test loss: 54.64508056640625\n",
            "Epoch: 170 | Train loss: 54.208553314208984 | Test loss: 54.467952728271484\n",
            "Epoch: 180 | Train loss: 54.03282165527344 | Test loss: 54.29083251953125\n",
            "Epoch: 190 | Train loss: 53.85708236694336 | Test loss: 54.113712310791016\n",
            "Epoch: 200 | Train loss: 53.68135452270508 | Test loss: 53.93658447265625\n",
            "Epoch: 210 | Train loss: 53.50562286376953 | Test loss: 53.75946807861328\n",
            "Epoch: 220 | Train loss: 53.329891204833984 | Test loss: 53.58234405517578\n",
            "Epoch: 230 | Train loss: 53.15415954589844 | Test loss: 53.40522003173828\n",
            "Epoch: 240 | Train loss: 52.97843551635742 | Test loss: 53.22810363769531\n",
            "Epoch: 250 | Train loss: 52.80270004272461 | Test loss: 53.05097579956055\n",
            "Epoch: 260 | Train loss: 52.62696838378906 | Test loss: 52.87384796142578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  print(model_0.forward(torch.tensor(7), torch.tensor(99), torch.tensor(1), torch.tensor(9), torch.tensor(1)))"
      ],
      "metadata": {
        "id": "R_Ih_NfhRyW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2yaWc2WUT6Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3208c02"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}